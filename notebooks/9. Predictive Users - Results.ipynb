{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1106aa94-fa42-48b4-8216-2af5ec5fd099",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 9. Predictive Users - Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69ac3b-682a-4f8e-8adf-5b3ab22bb128",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72b65f7-daa5-4050-bb7b-eee08b115654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9260b788-9f75-4144-8a0c-f82a90a0cd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Conor Mac\n",
      "[nltk_data]     Amhlaoibh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "languages = [\n",
    "    'arabic', 'azerbaijani', 'bengali', 'danish', 'dutch', 'english',\n",
    "    'finnish', 'french', 'german', 'greek', 'hungarian', 'indonesian',\n",
    "    'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian',\n",
    "    'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish'\n",
    "]\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "all_stopwords = set()\n",
    "for language in languages:\n",
    "    all_stopwords |= set(stopwords.words(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f79ff0-5400-4780-bc1b-774bba01a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_SAMPLE = '../data/samples/'\n",
    "PATH_SAMPLES = DIR_SAMPLE + 'review_users/%s_%s.csv'\n",
    "DIR_RESULT = '../data/results/bert/'\n",
    "PATH_RESULTS_HP = DIR_RESULT + 'review_users/hyperparams/eng_160k_%d_train.txt'\n",
    "PATH_RESULTS_OPT = DIR_RESULT + 'review_users/optimal/%s_10_%s.txt'\n",
    "PATH_RESULTS_BU = DIR_RESULT + 'review_users/best_users/data.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543c3f0-5312-4571-b7ee-b1ac9c2b53dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Reading and Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "68c25b5a-5258-4a2a-a6d6-2a0259cc3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, is_english=True):\n",
    "    if is_english:\n",
    "        text = text.lower()\n",
    "        stopword_list = english_stopwords\n",
    "    else:\n",
    "        stopword_list = all_stopwords\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text, re.UNICODE)\n",
    "    text = ' '.join([\n",
    "        word\n",
    "        for word in text.split()\n",
    "        if word not in stopword_list\n",
    "    ])\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e58712b2-26a4-42b3-9fe8-07784cf6bc12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(sample_name, seed=None):\n",
    "    train = pd.read_csv(PATH_SAMPLES % (sample_name, 'train'))[['uid', 'gid_mean_class', 'text']].reset_index(drop=True)\n",
    "    validation = pd.read_csv(PATH_SAMPLES % (sample_name, 'val'))[['uid', 'gid_mean_class', 'text']].reset_index(drop=True)\n",
    "    test = pd.read_csv(PATH_SAMPLES % (sample_name, 'test'))[['uid', 'gid_mean_class', 'text']].reset_index(drop=True)\n",
    "    if sample_name.startswith('eng'):\n",
    "        train['text'] = train['text'].apply(lambda text: preprocess_text(text, is_english=True))\n",
    "        validation['text'] = validation['text'].apply(lambda text: preprocess_text(text, is_english=True))\n",
    "        test['text'] = test['text'].apply(lambda text: preprocess_text(text, is_english=True))\n",
    "    else:\n",
    "        train['text'] = train['text'].apply(lambda text: preprocess_text(text, is_english=False))\n",
    "        validation['text'] = validation['text'].apply(lambda text: preprocess_text(text, is_english=False))\n",
    "        test['text'] = test['text'].apply(lambda text: preprocess_text(text, is_english=False))\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e065823-aa26-40be-9cde-ebb4d945b8df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef12654-86d6-47f7-8fd6-465ec182544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'eng_160k_6'\n",
    "seed = 1337\n",
    "train, validation, _ = read_data(sample_name, seed=seed)\n",
    "Xt, Yt = train['text'].tolist(), train['gid_mean_class'].tolist()\n",
    "Xv, Yv = validation['text'].tolist(), validation['gid_mean_class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cf3b3-55ad-49a0-965c-f4e4512879e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit TFIDF models first\n",
    "ngram_ranges = [(1, 2), (1, 3), (1, 4)]\n",
    "Xt_tfidfs, Xv_tfidfs = [], []\n",
    "for ngram_range in ngram_ranges:\n",
    "    tfidf = TfidfVectorizer(ngram_range=ngram_range, binary=True, smooth_idf=False)\n",
    "    Xt_tfidfs.append(tfidf.fit_transform(Xt))\n",
    "    Xv_tfidfs.append(tfidf.transform(Xv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d312ac-52d1-4059-9c07-3e9ec4feb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052e02a-73a5-40ed-9727-0f4d4c26d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['bl'] = {}\n",
    "bl_freq = DummyClassifier(strategy='most_frequent')\n",
    "scores = cross_val_score(bl_freq, Xt, Yt, scoring='accuracy', cv=5)\n",
    "mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "results['bl']['freq'] = (mean, std)\n",
    "bl_rand = DummyClassifier(strategy='stratified')\n",
    "scores = cross_val_score(bl_rand, Xt, Yt, scoring='accuracy', cv=5)\n",
    "mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "results['bl']['rand'] = (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10beff19-6003-445e-bb09-eb16bcf6ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ngram_range in enumerate(ngram_ranges):\n",
    "    print(f'=== TFIDF: ngram_range=(1,{ngram_range[1]}) ===')\n",
    "    Xt_tfidf = Xt_tfidfs[i]\n",
    "    Xv_tfidf = Xv_tfidfs[i]\n",
    "    results[ngram_range] = {}\n",
    "    # MultinomialNB\n",
    "    alphas = [0.01, 0.1, 1, 10]\n",
    "    results[ngram_range]['mnb'] = {}\n",
    "    for alpha in alphas:\n",
    "        print(f'>>> MultinomialNB (alpha={alpha}) <<<')\n",
    "        model = MultinomialNB(alpha=alpha)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['mnb'][alpha] = (mean, std)\n",
    "    # ComplementNB\n",
    "    alphas = [0.01, 0.1, 1, 10]\n",
    "    results[ngram_range]['cnb'] = {}\n",
    "    for alpha in alphas:\n",
    "        print(f'>>> ComplementNB (alpha={alpha}) <<<')\n",
    "        model = ComplementNB(alpha=alpha)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['cnb'][alpha] = (mean, std)\n",
    "    # SGDClassifier\n",
    "    alphas = [0.0001, 0.00001, 0.000001]\n",
    "    results[ngram_range]['sgd'] = {}\n",
    "    for alpha in alphas:\n",
    "        print(f'>>> SGDClassifier (alpha={alpha}) <<<')\n",
    "        model = SGDClassifier(penalty='l2', alpha=alpha, max_iter=100)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['sgd'][alpha] = (mean, std)\n",
    "    # LinearSVC\n",
    "    Cs = [0.01, 0.1, 1, 10]\n",
    "    results[ngram_range]['lsvc'] = {}\n",
    "    for C in Cs:\n",
    "        print(f'>>> LinearSVC (C={C}) <<<')\n",
    "        model = LinearSVC(penalty='l2', C=C, max_iter=100)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['lsvc'][C] = (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaddc52-8655-4bbf-a601-cbf009058d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972a105-dbe8-4533-b6b0-35234b16a67c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bceeec9b-8a6e-4fdf-b7af-f2e6e2ee8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cycler import cycler\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from matplotlib.ticker import AutoMinorLocator, ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5172d46c-018b-46f2-9e0f-a4803cb371b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE_S = 15\n",
    "FONT_SIZE_L = 18\n",
    "TICK_DIR = 'in'\n",
    "TICK_SIZE_S = 3.0\n",
    "TICK_SIZE_L = 5.0\n",
    "\n",
    "def init_plt():\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "    plt.rcParams['font.size'] = FONT_SIZE_S\n",
    "    plt.rcParams['legend.fontsize'] = FONT_SIZE_S\n",
    "    plt.rcParams['xtick.direction'] = TICK_DIR\n",
    "    plt.rcParams['ytick.direction'] = TICK_DIR\n",
    "    plt.rcParams['xtick.major.size'] = TICK_SIZE_L\n",
    "    plt.rcParams['xtick.minor.size'] = TICK_SIZE_S\n",
    "    plt.rcParams['ytick.major.size'] = TICK_SIZE_L\n",
    "    plt.rcParams['ytick.minor.size'] = TICK_SIZE_S\n",
    "    plt.rcParams['axes.linewidth'] = 0.8\n",
    "    plt.rcParams['axes.formatter.limits'] = (-9, 10)\n",
    "    plt.rcParams['legend.handlelength'] = 2.0\n",
    "    plt.rcParams['savefig.dpi'] = 400\n",
    "    plt.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "def init_ax(ax, only_vertical=False):\n",
    "    if not only_vertical:\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    return ax\n",
    "\n",
    "def remove_log_ticks(ax):\n",
    "    plt.rcParams['xtick.minor.size'] = 0\n",
    "\n",
    "init_plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "58a4e5e7-df39-4c03-89b0-5bd60d21c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_FIGS = '../report/figures/04_features/04_review_users/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e82e9d-472b-4b3f-8628-a4c120472d4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot Base Hyperparameter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505e60c-45c2-4be2-94c4-d1e3c84744b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result_to_data(result):\n",
    "    X, Y, E = [], [], []\n",
    "    for x, (y, e) in result.items():\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        E.append(e)\n",
    "    return X, Y, E\n",
    "\n",
    "def plot_base_hp_results(results):\n",
    "    # line styles\n",
    "    # set up subplots\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    plt.subplots_adjust(bottom=0, left=0, top=1, right=1, wspace=0.2)\n",
    "    p1 = fig.add_subplot(2, 2, 1)\n",
    "    p2 = fig.add_subplot(2, 2, 2)\n",
    "    p3 = fig.add_subplot(2, 2, (3, 4))\n",
    "    styles = (cycler('marker', ['^','o', 'D', 'x', '2']) * cycler('color', ['#aaa', '#111', '#666']))\n",
    "    p1.set_prop_cycle(styles)\n",
    "    p2.set_prop_cycle(styles)\n",
    "    p3.set_prop_cycle(styles)\n",
    "    # plot actual results\n",
    "    for label in ['mnb', 'cnb', 'sgd', 'lsvc']:\n",
    "        for N in [2, 3, 4]:\n",
    "            X, Y, E = convert_result_to_data(results[(1, N)][label])\n",
    "            p1.plot(X, Y, label=f'${N}$-gram {label.upper()}')\n",
    "            p2.plot(X, Y, label=f'${N}$-gram {label.upper()}')\n",
    "            p3.plot(X, Y, label=f'${N}$-gram {label.upper()}')\n",
    "    # plot baseline results\n",
    "    X_rng = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "    for label in ['freq', 'rand']:\n",
    "        Y = [results['bl'][label][0]] * len(X_rng)\n",
    "        E = [results['bl'][label][1]] * len(X_rng)\n",
    "        label_name = {'freq':'Frequent','rand':'Stratified'}[label]\n",
    "        p1.plot(X_rng, Y, label=f'Baseline {label_name}')\n",
    "        p2.plot(X_rng, Y, label=f'Baseline {label_name}')\n",
    "        p3.plot(X_rng, Y, label=f'Baseline {label_name}')\n",
    "    # plot configuration\n",
    "    # plot 1\n",
    "    p1.set_xlim([7e-7, 1.5e-4])\n",
    "    p1.set_ylim([0.3, 0.6])\n",
    "    p1.set_xscale('log')\n",
    "    p1.set_ylabel('Accuracy')\n",
    "    init_ax(p1, only_vertical=True)\n",
    "    remove_log_ticks(p1)\n",
    "    # plot 2\n",
    "    p2.set_xlim([7e-3, 1.5e1])\n",
    "    p2.set_ylim([0.3, 0.6])\n",
    "    p2.set_xscale('log')\n",
    "    init_ax(p2, only_vertical=True)\n",
    "    remove_log_ticks(p2)\n",
    "    # plot 3\n",
    "    p3.set_xlim([7e-7, 1.5e1])\n",
    "    p3.set_ylim([0, 0.7])\n",
    "    p3.set_xscale('log')\n",
    "    p3.set_xlabel(f'Hyperparameter ($\\\\alpha, C$)')\n",
    "    p3.set_ylabel('Accuracy')\n",
    "    init_ax(p3, only_vertical=True)\n",
    "    remove_log_ticks(p3)\n",
    "    # connect plots\n",
    "    p3.fill_between((1e-6, 1e-4), 0.3, 0.6, facecolor='#eaeaea')\n",
    "    p3.fill_between((1e-2, 1e1), 0.3, 0.6, facecolor='#eaeaea')\n",
    "    fig.add_artist(ConnectionPatch(xyA=(7e-7, 0.3), coordsA=p1.transData, xyB=(1e-6, 0.6), coordsB=p3.transData, color='#aaa'))\n",
    "    fig.add_artist(ConnectionPatch(xyA=(1.5e-4, 0.3), coordsA=p1.transData, xyB=(1e-4, 0.6), coordsB=p3.transData, color='#aaa'))\n",
    "    fig.add_artist(ConnectionPatch(xyA=(7e-3, 0.3), coordsA=p2.transData, xyB=(1e-2, 0.6), coordsB=p3.transData, color='#aaa'))\n",
    "    fig.add_artist(ConnectionPatch(xyA=(1.5e1, 0.3), coordsA=p2.transData, xyB=(1e1, 0.6), coordsB=p3.transData, color='#aaa'))\n",
    "    # finalise\n",
    "    p2.legend(loc='upper left', bbox_to_anchor=(1.025, 1.025))\n",
    "    plt.savefig(DIR_FIGS + f'plot_hyperparams_base.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7913540-6154-49e1-8be9-7bf2dfbec541",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_base_hp_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02301c-092c-43d5-a033-5d75bffb9dfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot Bert Hyperparameter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c06f5d-5838-4e1a-9209-c985ba5295c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_train_results(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = ast.literal_eval(f.readlines()[1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf027b2-ae07-49a9-8106-4dd6e9db0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bert_hp_results():\n",
    "    # set up plot\n",
    "    styles = (cycler('color', ['#aaa', '#111', '#666']) * cycler('marker', ['2', 'x']))\n",
    "    ax = plt.gca()\n",
    "    ax.set_prop_cycle(styles)\n",
    "    # load and plot results\n",
    "    batch_sizes = [16, 32, 64]\n",
    "    num_epochs = [2, 3, 4]\n",
    "    i = 0\n",
    "    for batch_size in batch_sizes:\n",
    "        Y1, Y2 = [], []\n",
    "        for num_epoch in num_epochs:\n",
    "            data = load_bert_train_results(PATH_RESULTS_HP % i)\n",
    "            Y1.append(data['accuracy'][-1])\n",
    "            Y2.append(data['val_accuracy'][-1])\n",
    "            i += 1\n",
    "        plt.plot(num_epochs, Y1, label=f'Training ($n = {batch_size}$)')\n",
    "        plt.plot(num_epochs, Y2, label=f'Validation ($n = {batch_size}$)')\n",
    "    # plot configuration\n",
    "    plt.xticks(num_epochs)\n",
    "    plt.ylim([0.3, 0.8])\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    # change legend order\n",
    "    hs, ls = ax.get_legend_handles_labels()\n",
    "    ixs = [1, 3, 5, 0, 2, 4]\n",
    "    plt.legend([hs[ix] for ix in ixs], [ls[ix] for ix in ixs], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    # save and show\n",
    "    plt.savefig(DIR_FIGS + f'plot_hyperparams_bert.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057cc84-05ae-4bb9-9366-f3e21d79ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bert_hp_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dae962-4ae3-4330-883f-70cfbac50e50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Full Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "77f47288-ea05-45dc-921a-a23b77179bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_test_results(sample_name):\n",
    "    path_train = PATH_RESULTS_OPT % (sample_name, 'train')\n",
    "    path_test = PATH_RESULTS_OPT % (sample_name, 'test')\n",
    "    with open(path_train, 'r') as f:\n",
    "        data = ast.literal_eval(f.readlines()[1])\n",
    "        train_acc = data['accuracy'][-1]\n",
    "        val_acc = data['val_accuracy'][-1]\n",
    "    with open(path_test, 'r') as f:\n",
    "        Yt, Yp, Yproba, uids = map(ast.literal_eval, f.readlines())\n",
    "    return train_acc, val_acc, Yt, Yp, np.array(Yproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "063cbcc7-5cf4-4030-991a-c078d025c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_results_for_sample(sample_name, seed=None):\n",
    "    # load sample data\n",
    "    train, validation, test = read_data(sample_name, seed=seed)\n",
    "    Xt, Yt = train['text'].tolist(), train['gid_mean_class'].tolist()\n",
    "    #Xv, Yv = validation['text'].tolist(), validation['gid_mean_class'].tolist()\n",
    "    Xv, Yv = test['text'].tolist(), test['gid_mean_class'].tolist()\n",
    "    # vectorise sample data\n",
    "    tfidf2 = TfidfVectorizer(ngram_range=(1, 2), binary=True, smooth_idf=False)\n",
    "    Xt_tfidf2 = tfidf2.fit_transform(Xt)\n",
    "    Xv_tfidf2 = tfidf2.transform(Xv)\n",
    "    # init results\n",
    "    results = {}\n",
    "    # get results for baseline\n",
    "    model_bl = DummyClassifier(strategy='most_frequent')\n",
    "    model_bl.fit(Xt, Yt)\n",
    "    results['bl'] = model_bl.score(Xv, Yv)\n",
    "    print('>>>', 'bl =', results['bl'])\n",
    "    # get results for MultinomialNB\n",
    "    model_mnb = MultinomialNB(alpha=0.1)\n",
    "    model_mnb.fit(Xt_tfidf2, Yt)\n",
    "    results['mnb'] = model_mnb.score(Xv_tfidf2, Yv)\n",
    "    print('>>>', 'mnb =', results['mnb'])\n",
    "    # get results for ComplementNB\n",
    "    model_cnb = ComplementNB(alpha=1)\n",
    "    model_cnb.fit(Xt_tfidf2, Yt)\n",
    "    results['cnb'] = model_cnb.score(Xv_tfidf2, Yv)\n",
    "    print('>>>', 'cnb =', results['cnb'])\n",
    "    # get results for SGDClassifier\n",
    "    model_sgd = SGDClassifier(penalty='l2', alpha=1e-5)\n",
    "    model_sgd.fit(Xt_tfidf2, Yt)\n",
    "    results['sgd'] = model_sgd.score(Xv_tfidf2, Yv)\n",
    "    print('>>>', 'sgd =', results['sgd'])\n",
    "    # get results for LinearSVC\n",
    "    model_lsvc = LinearSVC(penalty='l2', C=1)\n",
    "    model_lsvc.fit(Xt_tfidf2, Yt)\n",
    "    results['lsvc'] = model_lsvc.score(Xv_tfidf2, Yv)\n",
    "    print('>>>', 'lsvc =', results['lsvc'])\n",
    "    # load pre-gathered BERT results\n",
    "    _, _, Yt, Yp, _ = load_bert_test_results(sample_name)\n",
    "    results['bert'] = accuracy_score(Yt, Yp)\n",
    "    print('>>>', 'bert =', results['bert'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e768354e-7d77-417b-bc2e-da119ef83849",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = [\n",
    "    'eng_160k_6', 'eng_160k_3',\n",
    "    'any_160k_6', 'any_160k_3',\n",
    "]\n",
    "seed = 1337\n",
    "test_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5b1c0-a5a4-4c4c-9c66-ceb1c5bf6693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    print(f'=== {sample_name} ===')\n",
    "    test_results[sample_name] = get_base_results_for_sample(sample_name, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfcaf0-1aae-4d0c-98ff-380a29a8fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b33a4f0-ab97-48d3-9096-4dcaafd55e88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot Sample Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d486b-751f-4f0f-af0f-e0d3c15c591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_scores(sample_name, results):\n",
    "    keys_to_labels = {\n",
    "        'bl': 'Baseline', 'mnb': 'MNB', 'cnb': 'CNB',\n",
    "        'sgd': 'SGD', 'lsvc': 'SVC', 'bert': 'BERT'\n",
    "    }\n",
    "    X, Y, labels = [], [], []\n",
    "    for i, (key, value) in enumerate(results[sample_name].items()):\n",
    "        X.append(i)\n",
    "        Y.append(value)\n",
    "        labels.append(keys_to_labels[key])\n",
    "    plt.rcParams['xtick.direction'] = 'out'\n",
    "    ax = plt.gca()\n",
    "    ax = init_ax(ax, only_vertical=True)\n",
    "    plt.bar(X, Y, color='darkgrey')\n",
    "    ymin = 0.2 if results[sample_name]['bl'] < 0.55 else 0.7\n",
    "    plt.ylim([ymin, 1.0])\n",
    "    plt.xticks(X, labels)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Model')\n",
    "    plt.savefig(DIR_FIGS + f'bars_optimal_{sample_name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847d580-07e7-48ad-8ce7-83c41cb6152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    plot_sample_scores(sample_name, test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8ed73-eb2a-4b76-bd8b-159095ffcf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot ROC and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2cee92c-b1d6-4aeb-9afb-05bbbcec40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_roc_cm(sample_name, seed=None, class_reports=False):\n",
    "    # class setup\n",
    "    num_classes = int(sample_name[-1])\n",
    "    classes = list(range(num_classes))\n",
    "    if num_classes == 6:\n",
    "        disp_labels = ['N', 'MN', 'M', 'MP', 'P', 'VP']\n",
    "    else:\n",
    "        disp_labels = ['N', 'M', 'P']\n",
    "    # load sample data\n",
    "    train, validation, test = read_data(sample_name, seed=seed)\n",
    "    Xt, Yt = train['text'].tolist(), train['gid_mean_class'].tolist()\n",
    "    #Xv, Yv = validation['text'].tolist(), validation['gid_mean_class'].tolist()\n",
    "    Xv, Yv = test['text'].tolist(), test['gid_mean_class'].tolist()\n",
    "    # vectorise sample data\n",
    "    tfidf2 = TfidfVectorizer(ngram_range=(1, 2), binary=True, smooth_idf=False)\n",
    "    Xt_tfidf2 = tfidf2.fit_transform(Xt)\n",
    "    Xv_tfidf2 = tfidf2.transform(Xv)\n",
    "    # get baseline results\n",
    "    model_bl = DummyClassifier(strategy='most_frequent')\n",
    "    model_bl.fit(Xt, Yt)\n",
    "    Ypred_bl = model_bl.predict(Xv)\n",
    "    Yp_bl = model_bl.predict_proba(Xv)[:,1]\n",
    "    #fpr_bl, tpr_bl, _ = roc_curve(Yv, Yp_bl, pos_label=1)\n",
    "    #prec_bl, rec_bl, _ = precision_recall_curve(Yv, Yp_bl, pos_label=1)\n",
    "    # get model results\n",
    "    comp_label = 'SGD'\n",
    "    model_comp = SGDClassifier(penalty='l2', alpha=1e-5)\n",
    "    model_comp.fit(Xt_tfidf2, Yt)\n",
    "    Ypred_comp = model_comp.predict(Xv_tfidf2)\n",
    "    Yp_comp = model_comp.decision_function(Xv_tfidf2)\n",
    "    #fpr_comp, tpr_comp, _ = roc_curve(Yv, Yp_comp, pos_label=1)\n",
    "    #prec_comp, rec_comp, _ = precision_recall_curve(Yv, Yp_comp, pos_label=1)\n",
    "    #auc_comp = round(auc(fpr_comp, tpr_comp), 3)\n",
    "    # load pre-gathered bert results\n",
    "    _, _, Yt_bert, Yp_bert, Yp_proba = load_bert_test_results(sample_name)\n",
    "    #fpr_bert, tpr_bert, _ = roc_curve(Yt_bert, Yp_proba[:,1], pos_label=1)\n",
    "    #prec_bert, rec_bert, _ = precision_recall_curve(Yt_bert, Yp_proba[:,1], pos_label=1)\n",
    "    #auc_bert = round(auc(fpr_bert, tpr_bert), 3)\n",
    "    # print classification reports\n",
    "    if class_reports:\n",
    "        print(classification_report(Yv, Ypred_bl, zero_division=0))\n",
    "        print(classification_report(Yv, Ypred_comp, zero_division=0))\n",
    "        print(classification_report(Yv, Yp_bert, zero_division=0))\n",
    "        return\n",
    "    \"\"\"\n",
    "    # plot roc curves\n",
    "    Yt_bin = label_binarize(Yt, classes=classes)\n",
    "    Yv_bin = label_binarize(Yv, classes=classes)\n",
    "    ovr_model_comp = OneVsRestClassifier(SGDClassifier(penalty='l2', alpha=1e-5))\n",
    "    ovr_model_comp.fit(Xt_tfidf2, Yt_bin)\n",
    "    ovr_Yp_comp = ovr_model_comp.decision_function(Xv_tfidf2)\n",
    "    ovr_fpr_comp, ovr_tpr_comp = {}, {}\n",
    "    for i in range(num_classes):\n",
    "        ovr_fpr_comp[i], ovr_tpr_comp[i], _ = roc_curve(Yv_bin[:,i], ovr_Yp_comp[:,i])\n",
    "    ovr_fpr_comp['micro'], ovr_tpr_comp['micro'], _ = roc_curve(Yv_bin.ravel(), ovr_Yp_comp.ravel())\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(ovr_fpr_comp[i], ovr_tpr_comp[i], linestyle='--', color='#666', label=disp_labels[i])\n",
    "    #plt.plot(fpr_bert, tpr_bert, linestyle='--', color='#666', label=f'BERT (AUC $= {auc_bert}$)')\n",
    "    #plt.plot(fpr_comp, tpr_comp, linestyle='--', color='#111', label=f'{comp_label} (AUC $= {auc_comp}$)')\n",
    "    #plt.plot(fpr_bl, tpr_bl, linestyle='--', color='#aaa', label='Baseline')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    #plt.savefig(DIR_FIGS + f'roc_optimal_{sample_name}.png')\n",
    "    plt.show()\n",
    "    # plot precision/recall\n",
    "    plt.plot(rec_bert, prec_bert, linestyle='--', color='#666', label=f'BERT')\n",
    "    plt.plot(rec_comp, prec_comp, linestyle='--', color='#111', label=f'{comp_label}')\n",
    "    plt.plot(rec_bl, prec_bl, linestyle='--', color='#aaa', label=f'Baseline')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.savefig(DIR_FIGS + f'prec_optimal_{sample_name}.png')\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    # confusion matrices\n",
    "    plt.rcParams['xtick.direction'] = 'out'\n",
    "    plt.rcParams['ytick.direction'] = 'out'\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n",
    "    plt.subplots_adjust(bottom=0, left=0, top=1, right=1, wspace=-0.4)\n",
    "    def empty_func(_, ax=None): return\n",
    "    temp = fig.colorbar\n",
    "    fig.colorbar = empty_func\n",
    "    ax1.set_title('BERT')\n",
    "    ax2.set_title(f'{comp_label}')\n",
    "    cm_bert = confusion_matrix(Yt_bert, Yp_bert, labels=classes)\n",
    "    disp_bert = ConfusionMatrixDisplay(cm_bert, display_labels=disp_labels)\n",
    "    disp_bert.plot(cmap='Greys', ax=ax1)\n",
    "    fig.colorbar = temp\n",
    "    cm_comp = confusion_matrix(Yv, Ypred_comp, labels=classes)\n",
    "    disp_comp = ConfusionMatrixDisplay(cm_comp, display_labels=disp_labels)\n",
    "    disp_comp.plot(cmap='Greys', ax=ax2)\n",
    "    plt.savefig(DIR_FIGS + f'cm_optimal_{sample_name}.png')\n",
    "    plt.show()\n",
    "    init_plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c5ce6-869a-409b-b853-d27af528627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    plot_sample_roc_cm(sample_name, seed=seed, class_reports=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fdabe-b0b3-49e1-a976-2af0e2da2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    print(f'=== {sample_name} ===')\n",
    "    plot_sample_roc_cm(sample_name, seed=seed, class_reports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314469de-3875-4c72-b9f2-470694c96ecc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Best Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "abff1932-cf94-4c70-a51e-a9ac53be001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bert_data_with_uids(sample_name):\n",
    "    path_test = PATH_RESULTS_OPT % (sample_name, 'test')\n",
    "    with open(path_test, 'r') as f:\n",
    "        Yt, Yp, _, uids = map(ast.literal_eval, f.readlines())\n",
    "    return Yt, Yp, uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6379d368-66af-4cf4-9f33-8a4f384b0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data(sample_name, seed=None):\n",
    "    # get base predictions\n",
    "    train, validation, test = read_data(sample_name, seed=seed)\n",
    "    Xt, Yt = train['text'].tolist(), train['gid_mean_class'].tolist()\n",
    "    Xv, Yv, Yv_uids = test['text'].tolist(), test['gid_mean_class'].tolist(), test['uid'].tolist()\n",
    "    tfidf2 = TfidfVectorizer(ngram_range=(1, 2), binary=True, smooth_idf=False)\n",
    "    Xt_tfidf2 = tfidf2.fit_transform(Xt)\n",
    "    Xv_tfidf2 = tfidf2.transform(Xv)\n",
    "    Yp_bl = DummyClassifier(strategy='most_frequent').fit(Xt, Yt).predict(Xv)\n",
    "    Yp_comp = SGDClassifier(penalty='l2', alpha=1e-5).fit(Xt_tfidf2, Yt).predict(Xv_tfidf2)\n",
    "    # get bert predictions\n",
    "    Yv_bert, Yp_bert, Yp_uids = read_bert_data_with_uids(sample_name)\n",
    "    return {\n",
    "        'true_base': Yv,\n",
    "        'true_bert': Yv_bert,\n",
    "        'true_uids': Yv_uids,\n",
    "        'pred_bl':   Yp_bl.tolist(),\n",
    "        'pred_comp': Yp_comp.tolist(),\n",
    "        'pred_bert': Yp_bert,\n",
    "        'pred_uids': Yp_uids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c3fc392e-fe97-4700-99c6-680835fab3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_users(sample_name, data, seed=None):\n",
    "    # class setup\n",
    "    num_classes = int(sample_name[-1])\n",
    "    classes = list(range(num_classes))\n",
    "    if num_classes == 6: disp_labels = ['N', 'MN', 'M', 'MP', 'P', 'VP']\n",
    "    else: disp_labels = ['N', 'M', 'P']\n",
    "    # calculate user accuracies\n",
    "    uids = data['true_uids']\n",
    "    users = {}\n",
    "    for i, uid in enumerate(uids):\n",
    "        if uid not in users:\n",
    "            users[uid] = {\n",
    "                'N': 0,\n",
    "                'cor_bl': 0,\n",
    "                'cor_comp': 0,\n",
    "                'cor_bert': 0,\n",
    "                'dist': [0] * num_classes\n",
    "            }\n",
    "        users[uid]['N'] += 1\n",
    "        true = data['true_base'][i]\n",
    "        users[uid]['dist'][true] += 1\n",
    "        users[uid]['cor_bl'] += 1 if true == data['pred_bl'][i] else 0\n",
    "        users[uid]['cor_comp'] += 1 if true == data['pred_comp'][i] else 0\n",
    "        users[uid]['cor_bert'] += 1 if true == data['pred_bert'][i] else 0\n",
    "    for uid in users.keys():\n",
    "        users[uid]['acc_bl'] = users[uid]['cor_bl'] / users[uid]['N']\n",
    "        users[uid]['acc_comp'] = users[uid]['cor_comp'] / users[uid]['N']\n",
    "        users[uid]['acc_bert'] = users[uid]['cor_bert'] / users[uid]['N']\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "10ab8c08-4f2e-4626-8104-4687a362d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "53a43bfa-8a6e-468e-954e-54053c673862",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    user_results[sample_name] = best_users(sample_name, get_user_data(sample_name, seed=seed), seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2fd162a3-290b-4f9c-b3c0-b0aa86458ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_RESULTS_BU, 'wb+') as f:\n",
    "    pickle.dump(user_results, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123b58c3-dfef-4034-956d-8a68c088d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_RESULTS_BU, 'rb') as f:\n",
    "    user_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fcc25-7835-4620-a659-ec9a3a724a17",
   "metadata": {},
   "source": [
    "## Plot BERT Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "39a2a7ff-3a9b-4353-9483-08185e0f4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_users_simple(sample_name, data):\n",
    "    values = []\n",
    "    for user_results in data[sample_name].values():\n",
    "        values.append([\n",
    "            user_results['acc_bl'],\n",
    "            user_results['acc_comp'],\n",
    "            user_results['acc_bert']\n",
    "        ])\n",
    "    N = len(values)\n",
    "    df = pd.DataFrame(values, columns=['bl', 'comp', 'bert'])\n",
    "    # simple plot\n",
    "    steps = 100\n",
    "    X = []\n",
    "    Y = [[], [], []]\n",
    "    for i in range(steps + 1):\n",
    "        min_acc = i * (1 / steps)\n",
    "        X.append(min_acc)\n",
    "        Y[0].append(len(df[df['bl'] >= min_acc].index) / N)\n",
    "        Y[1].append(len(df[df['comp'] >= min_acc].index) / N)\n",
    "        Y[2].append(len(df[df['bert'] >= min_acc].index) / N)\n",
    "    plt.plot(X, Y[0], label='Baseline', color='#aaa', linestyle='-')\n",
    "    plt.plot(X, Y[1], label='SGD', color='#666', linestyle='--')\n",
    "    plt.plot(X, Y[2], label='BERT', color='#111', linestyle='-.')\n",
    "    plt.legend()\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('Minimum accuracy')\n",
    "    plt.ylabel('Percentage of users')\n",
    "    plt.savefig(DIR_FIGS + f'plot_simple_{sample_name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a052b4dc-e0a1-4e3b-a46e-bf2abdda4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_users_complex(sample_name, data):\n",
    "    values = []\n",
    "    for user_results in data[sample_name].values():\n",
    "        values.append([\n",
    "            user_results['acc_bl'],\n",
    "            user_results['acc_comp'],\n",
    "            user_results['acc_bert']\n",
    "        ])\n",
    "    N = len(values)\n",
    "    df = pd.DataFrame(values, columns=['bl', 'comp', 'bert'])\n",
    "    # complex plot\n",
    "    pcts = [1.1, 1.2, 1.3, 1.4]\n",
    "    lbls = ['10', '20', '30', '40']\n",
    "    for i in range(4):\n",
    "        steps = 100\n",
    "        X = []\n",
    "        Y = [[], []]\n",
    "        for j in range(steps + 1):\n",
    "            min_acc_alg = j * (1 / steps)\n",
    "            min_acc_bl = min_acc_alg / pcts[i]\n",
    "            X.append(min_acc_alg)\n",
    "            Y[0].append(len(df[(df['bl'] >= min_acc_bl) & (df['comp'] >= min_acc_alg)].index) / N)\n",
    "            Y[1].append(len(df[(df['bl'] >= min_acc_bl) & (df['bert'] >= min_acc_alg)].index) / N)\n",
    "        plt.plot(X, Y[0], label='SGD', color='#666', linestyle='--')\n",
    "        plt.plot(X, Y[1], label='BERT', color='#111', linestyle='-.')\n",
    "        plt.legend()\n",
    "        if sample_name[-1] == '6':\n",
    "            plt.xlim([0.48, 1.0])\n",
    "            plt.ylim([0.0, 0.5])\n",
    "        else:\n",
    "            plt.xlim([0.68, 1.0])\n",
    "            plt.ylim([0.2, 0.8])\n",
    "        plt.xlabel(f'Minimum accuracy ($\\\\ge{lbls[i]}\\\\%$ more than BL)')\n",
    "        plt.ylabel('Percentage of users')\n",
    "        plt.savefig(DIR_FIGS + f'plot_complex_{sample_name}_{lbls[i]}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a3f3d-c70c-4cbb-92fd-c9f68988c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    #plot_best_users_simple(sample_name, user_results)\n",
    "    plot_best_users_complex(sample_name, user_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
