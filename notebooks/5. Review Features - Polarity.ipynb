{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1106aa94-fa42-48b4-8216-2af5ec5fd099",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Review Features: Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69ac3b-682a-4f8e-8adf-5b3ab22bb128",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72b65f7-daa5-4050-bb7b-eee08b115654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB, MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9260b788-9f75-4144-8a0c-f82a90a0cd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Conor Mac\n",
      "[nltk_data]     Amhlaoibh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "languages = [\n",
    "    'arabic', 'azerbaijani', 'bengali', 'danish', 'dutch', 'english',\n",
    "    'finnish', 'french', 'german', 'greek', 'hungarian', 'indonesian',\n",
    "    'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian',\n",
    "    'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish'\n",
    "]\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "all_stopwords = set()\n",
    "for language in languages:\n",
    "    all_stopwords |= set(stopwords.words(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f79ff0-5400-4780-bc1b-774bba01a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_SAMPLE = '../data/samples/'\n",
    "PATH_SAMPLES = DIR_SAMPLE + 'review_sentiment/%s.csv'\n",
    "DIR_RESULT = '../data/results/bert/'\n",
    "PATH_RESULTS_HP = DIR_RESULT + 'review_polarity/hyperparams/eng_eq_any_100000_%d_train.txt'\n",
    "PATH_RESULTS_OPT = DIR_RESULT + 'review_polarity/optimal/%s_10_%s.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543c3f0-5312-4571-b7ee-b1ac9c2b53dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Reading and Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c25b5a-5258-4a2a-a6d6-2a0259cc3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, is_english=True):\n",
    "    if is_english:\n",
    "        text = text.lower()\n",
    "        stopword_list = english_stopwords\n",
    "    else:\n",
    "        stopword_list = all_stopwords\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text, re.UNICODE)\n",
    "    text = ' '.join([\n",
    "        word\n",
    "        for word in text.split()\n",
    "        if word not in stopword_list\n",
    "    ])\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e58712b2-26a4-42b3-9fe8-07784cf6bc12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(sample_name, train_size=0.9, seed=None):\n",
    "    df = pd.read_csv(PATH_SAMPLES % sample_name)[['polarity', 'text']].reset_index(drop=True)\n",
    "    if sample_name.startswith('eng'):\n",
    "        df['text'] = df['text'].apply(lambda text: preprocess_text(text, is_english=True))\n",
    "    else:\n",
    "        df['text'] = df['text'].apply(lambda text: preprocess_text(text, is_english=False))\n",
    "    train, validation = train_test_split(df, train_size=train_size, random_state=seed)\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e065823-aa26-40be-9cde-ebb4d945b8df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef12654-86d6-47f7-8fd6-465ec182544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'eng_eq_any_100000'\n",
    "seed = 1337\n",
    "train, validation = read_data(sample_name, seed=seed)\n",
    "Xt, Yt = train['text'].tolist(), train['polarity'].tolist()\n",
    "Xv, Yv = validation['text'].tolist(), validation['polarity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cf3b3-55ad-49a0-965c-f4e4512879e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit TFIDF models first\n",
    "ngram_ranges = [(1, 2), (1, 3), (1, 4)]\n",
    "Xt_tfidfs, Xv_tfidfs = [], []\n",
    "for ngram_range in ngram_ranges:\n",
    "    tfidf = TfidfVectorizer(ngram_range=ngram_range, binary=True, smooth_idf=False)\n",
    "    Xt_tfidfs.append(tfidf.fit_transform(Xt))\n",
    "    Xv_tfidfs.append(tfidf.transform(Xv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d312ac-52d1-4059-9c07-3e9ec4feb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052e02a-73a5-40ed-9727-0f4d4c26d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['bl'] = {}\n",
    "bl_freq = DummyClassifier(strategy='most_frequent')\n",
    "scores = cross_val_score(bl_freq, Xt, Yt, scoring='accuracy', cv=5)\n",
    "mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "results['bl']['freq'] = (mean, std)\n",
    "bl_rand = DummyClassifier(strategy='uniform')\n",
    "scores = cross_val_score(bl_rand, Xt, Yt, scoring='accuracy', cv=5)\n",
    "mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "results['bl']['rand'] = (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10beff19-6003-445e-bb09-eb16bcf6ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ngram_range in enumerate(ngram_ranges):\n",
    "    print(f'=== TFIDF: ngram_range=(1,{ngram_range[1]}) ===')\n",
    "    Xt_tfidf = Xt_tfidfs[i]\n",
    "    Xv_tfidf = Xv_tfidfs[i]\n",
    "    results[ngram_range] = {}\n",
    "    # MultinomialNB\n",
    "    alphas = [0.01, 0.1, 1, 10]\n",
    "    results[ngram_range]['mnb'] = {}\n",
    "    for alpha in alphas:\n",
    "        print(f'>>> MultinomialNB (alpha={alpha}) <<<')\n",
    "        model = MultinomialNB(alpha=alpha)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['mnb'][alpha] = (mean, std)\n",
    "    # ComplementNB\n",
    "    alphas = [0.01, 0.1, 1, 10]\n",
    "    results[ngram_range]['cnb'] = {}\n",
    "    for alpha in alphas:\n",
    "        print(f'>>> ComplementNB (alpha={alpha}) <<<')\n",
    "        model = ComplementNB(alpha=alpha)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['cnb'][alpha] = (mean, std)\n",
    "    # SGDClassifier\n",
    "    alphas = [0.0001, 0.00001, 0.000001]\n",
    "    results[ngram_range]['sgd'] = {}\n",
    "    for alpha in alphas:\n",
    "        print(f'>>> SGDClassifier (alpha={alpha}) <<<')\n",
    "        model = SGDClassifier(penalty='l2', alpha=alpha, max_iter=100)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['sgd'][alpha] = (mean, std)\n",
    "    # LinearSVC\n",
    "    Cs = [0.01, 0.1, 1, 10]\n",
    "    results[ngram_range]['lsvc'] = {}\n",
    "    for C in Cs:\n",
    "        print(f'>>> LinearSVC (C={C}) <<<')\n",
    "        model = LinearSVC(penalty='l2', C=C, max_iter=100)\n",
    "        scores = cross_val_score(model, Xt_tfidf, Yt, scoring='accuracy', cv=5)\n",
    "        mean, std = round(scores.mean(), 4), round(scores.std(), 4)\n",
    "        print(f'mean={mean}, std={std}')\n",
    "        results[ngram_range]['lsvc'][C] = (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaddc52-8655-4bbf-a601-cbf009058d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972a105-dbe8-4533-b6b0-35234b16a67c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bceeec9b-8a6e-4fdf-b7af-f2e6e2ee8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cycler import cycler\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from matplotlib.ticker import AutoMinorLocator, ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5172d46c-018b-46f2-9e0f-a4803cb371b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE_S = 15\n",
    "FONT_SIZE_L = 18\n",
    "TICK_DIR = 'in'\n",
    "TICK_SIZE_S = 3.0\n",
    "TICK_SIZE_L = 5.0\n",
    "\n",
    "def init_plt():\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "    plt.rcParams['font.size'] = FONT_SIZE_S\n",
    "    plt.rcParams['legend.fontsize'] = FONT_SIZE_S\n",
    "    plt.rcParams['xtick.direction'] = TICK_DIR\n",
    "    plt.rcParams['ytick.direction'] = TICK_DIR\n",
    "    plt.rcParams['xtick.major.size'] = TICK_SIZE_L\n",
    "    plt.rcParams['xtick.minor.size'] = TICK_SIZE_S\n",
    "    plt.rcParams['ytick.major.size'] = TICK_SIZE_L\n",
    "    plt.rcParams['ytick.minor.size'] = TICK_SIZE_S\n",
    "    plt.rcParams['axes.linewidth'] = 0.8\n",
    "    plt.rcParams['axes.formatter.limits'] = (-9, 10)\n",
    "    plt.rcParams['legend.handlelength'] = 2.0\n",
    "    plt.rcParams['savefig.dpi'] = 400\n",
    "    plt.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "def init_ax(ax, only_vertical=False):\n",
    "    if not only_vertical:\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    return ax\n",
    "\n",
    "def remove_log_ticks(ax):\n",
    "    plt.rcParams['xtick.minor.size'] = 0\n",
    "\n",
    "init_plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a4e5e7-df39-4c03-89b0-5bd60d21c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_FIGS = '../figures/04_features/review_polarity/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e82e9d-472b-4b3f-8628-a4c120472d4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot Base Hyperparameter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505e60c-45c2-4be2-94c4-d1e3c84744b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result_to_data(result):\n",
    "    X, Y, E = [], [], []\n",
    "    for x, (y, e) in result.items():\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        E.append(e)\n",
    "    return X, Y, E\n",
    "\n",
    "def plot_base_hp_results(results):\n",
    "    # line styles\n",
    "    # set up subplots\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    plt.subplots_adjust(bottom=0, left=0, top=1, right=1, wspace=0.2)\n",
    "    p1 = fig.add_subplot(2, 2, 1)\n",
    "    p2 = fig.add_subplot(2, 2, 2)\n",
    "    p3 = fig.add_subplot(2, 2, (3, 4))\n",
    "    styles = (cycler('marker', ['^','o', 'D', 'x', '2']) * cycler('color', ['#aaa', '#111', '#666']))\n",
    "    p1.set_prop_cycle(styles)\n",
    "    p2.set_prop_cycle(styles)\n",
    "    p3.set_prop_cycle(styles)\n",
    "    # plot actual results\n",
    "    for label in ['mnb', 'cnb', 'sgd', 'lsvc']:\n",
    "        for N in [2, 3, 4]:\n",
    "            X, Y, E = convert_result_to_data(results[(1, N)][label])\n",
    "            p1.plot(X, Y, label=f'${N}$-gram {label.upper()}')\n",
    "            p2.plot(X, Y, label=f'${N}$-gram {label.upper()}')\n",
    "            p3.plot(X, Y, label=f'${N}$-gram {label.upper()}')\n",
    "    # plot baseline results\n",
    "    X_rng = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "    for label in ['freq', 'rand']:\n",
    "        Y = [results['bl'][label][0]] * len(X_rng)\n",
    "        E = [results['bl'][label][1]] * len(X_rng)\n",
    "        label_name = {'freq':'Frequent','rand':'Random'}[label]\n",
    "        p1.plot(X_rng, Y, label=f'Baseline {label_name}')\n",
    "        p2.plot(X_rng, Y, label=f'Baseline {label_name}')\n",
    "        p3.plot(X_rng, Y, label=f'Baseline {label_name}')\n",
    "    # plot configuration\n",
    "    # plot 1\n",
    "    p1.set_xlim([7e-7, 1.5e-4])\n",
    "    p1.set_ylim([0.7, 0.85])\n",
    "    p1.set_xscale('log')\n",
    "    p1.set_ylabel('Accuracy')\n",
    "    init_ax(p1, only_vertical=True)\n",
    "    remove_log_ticks(p1)\n",
    "    # plot 2\n",
    "    p2.set_xlim([7e-3, 1.5e1])\n",
    "    p2.set_ylim([0.7, 0.85])\n",
    "    p2.set_xscale('log')\n",
    "    init_ax(p2, only_vertical=True)\n",
    "    remove_log_ticks(p2)\n",
    "    # plot 3\n",
    "    p3.set_xlim([7e-7, 1.5e1])\n",
    "    p3.set_ylim([0.4, 1.0])\n",
    "    p3.set_xscale('log')\n",
    "    p3.set_xlabel(f'Hyperparameter ($\\\\alpha, C$)')\n",
    "    p3.set_ylabel('Accuracy')\n",
    "    init_ax(p3, only_vertical=True)\n",
    "    remove_log_ticks(p3)\n",
    "    # connect plots\n",
    "    p3.fill_between((1e-6, 1e-4), 0.7, 0.85, facecolor='#eaeaea')\n",
    "    p3.fill_between((1e-2, 1e1), 0.7, 0.85, facecolor='#eaeaea')\n",
    "    fig.add_artist(ConnectionPatch(xyA=(7e-7, 0.7), coordsA=p1.transData, xyB=(1e-6, 0.85), coordsB=p3.transData, color='#aaa'))\n",
    "    fig.add_artist(ConnectionPatch(xyA=(1.5e-4, 0.7), coordsA=p1.transData, xyB=(1e-4, 0.85), coordsB=p3.transData, color='#aaa'))\n",
    "    fig.add_artist(ConnectionPatch(xyA=(7e-3, 0.7), coordsA=p2.transData, xyB=(1e-2, 0.85), coordsB=p3.transData, color='#aaa'))\n",
    "    fig.add_artist(ConnectionPatch(xyA=(1.5e1, 0.7), coordsA=p2.transData, xyB=(1e1, 0.85), coordsB=p3.transData, color='#aaa'))\n",
    "    # finalise\n",
    "    p2.legend(loc='upper left', bbox_to_anchor=(1.025, 1.025))\n",
    "    plt.savefig(DIR_FIGS + f'plot_hyperparams_base.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7913540-6154-49e1-8be9-7bf2dfbec541",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_base_hp_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02301c-092c-43d5-a033-5d75bffb9dfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plot Bert Hyperparameter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c06f5d-5838-4e1a-9209-c985ba5295c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_train_results(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = ast.literal_eval(f.readlines()[1])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf027b2-ae07-49a9-8106-4dd6e9db0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bert_hp_results():\n",
    "    # set up plot\n",
    "    styles = (cycler('color', ['#aaa', '#111', '#666']) * cycler('marker', ['2', 'x']))\n",
    "    ax = plt.gca()\n",
    "    ax.set_prop_cycle(styles)\n",
    "    # load and plot results\n",
    "    batch_sizes = [16, 32, 64]\n",
    "    num_epochs = [2, 3, 4]\n",
    "    i = 0\n",
    "    for batch_size in batch_sizes:\n",
    "        Y1, Y2 = [], []\n",
    "        for num_epoch in num_epochs:\n",
    "            data = load_bert_train_results(PATH_RESULTS_HP % i)\n",
    "            Y1.append(data['accuracy'][-1])\n",
    "            Y2.append(data['val_accuracy'][-1])\n",
    "            i += 1\n",
    "        plt.plot(num_epochs, Y1, label=f'Training ($n = {batch_size}$)')\n",
    "        plt.plot(num_epochs, Y2, label=f'Validation ($n = {batch_size}$)')\n",
    "    # plot configuration\n",
    "    plt.xticks(num_epochs)\n",
    "    plt.ylim([0.8, 1.0])\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    # change legend order\n",
    "    hs, ls = ax.get_legend_handles_labels()\n",
    "    ixs = [1, 3, 5, 0, 2, 4]\n",
    "    plt.legend([hs[ix] for ix in ixs], [ls[ix] for ix in ixs], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    # save and show\n",
    "    plt.savefig(DIR_FIGS + f'plot_hyperparams_bert.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057cc84-05ae-4bb9-9366-f3e21d79ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bert_hp_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dae962-4ae3-4330-883f-70cfbac50e50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Full Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77f47288-ea05-45dc-921a-a23b77179bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert_test_results(sample_name):\n",
    "    path_train = PATH_RESULTS_OPT % (sample_name, 'train')\n",
    "    path_test = PATH_RESULTS_OPT % (sample_name, 'test')\n",
    "    with open(path_train, 'r') as f:\n",
    "        data = ast.literal_eval(f.readlines()[1])\n",
    "        train_acc = data['accuracy'][-1]\n",
    "        val_acc = data['val_accuracy'][-1]\n",
    "    with open(path_test, 'r') as f:\n",
    "        Yt, Yp, Yproba = map(ast.literal_eval, f.readlines())\n",
    "    return train_acc, val_acc, Yt, Yp, np.array(Yproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063cbcc7-5cf4-4030-991a-c078d025c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_results_for_sample(sample_name, seed=None):\n",
    "    # load sample data\n",
    "    train, validation = read_data(sample_name, seed=seed)\n",
    "    Xt, Yt = train['text'].tolist(), train['polarity'].tolist()\n",
    "    Xv, Yv = validation['text'].tolist(), validation['polarity'].tolist()\n",
    "    # vectorise sample data\n",
    "    tfidf3 = TfidfVectorizer(ngram_range=(1, 3), binary=True, smooth_idf=False)\n",
    "    Xt_tfidf3 = tfidf3.fit_transform(Xt)\n",
    "    Xv_tfidf3 = tfidf3.transform(Xv)\n",
    "    tfidf4 = TfidfVectorizer(ngram_range=(1, 4), binary=True, smooth_idf=False)\n",
    "    Xt_tfidf4 = tfidf4.fit_transform(Xt)\n",
    "    Xv_tfidf4 = tfidf4.transform(Xv)\n",
    "    # init results\n",
    "    results = {}\n",
    "    # get results for baseline\n",
    "    model_bl = DummyClassifier(strategy='most_frequent')\n",
    "    model_bl.fit(Xt, Yt)\n",
    "    results['bl'] = model_bl.score(Xv, Yv)\n",
    "    print('>>>', 'bl =', results['bl'])\n",
    "    # get results for MultinomialNB\n",
    "    model_mnb = MultinomialNB(alpha=1)\n",
    "    model_mnb.fit(Xt_tfidf4, Yt)\n",
    "    results['mnb'] = model_mnb.score(Xv_tfidf4, Yv)\n",
    "    print('>>>', 'mnb =', results['mnb'])\n",
    "    # get results for ComplementNB\n",
    "    model_cnb = ComplementNB(alpha=1)\n",
    "    model_cnb.fit(Xt_tfidf4, Yt)\n",
    "    results['cnb'] = model_cnb.score(Xv_tfidf4, Yv)\n",
    "    print('>>>', 'cnb =', results['cnb'])\n",
    "    # get results for SGDClassifier\n",
    "    model_sgd = SGDClassifier(penalty='l2', alpha=1e-5)\n",
    "    model_sgd.fit(Xt_tfidf3, Yt)\n",
    "    results['sgd'] = model_sgd.score(Xv_tfidf3, Yv)\n",
    "    print('>>>', 'sgd =', results['sgd'])\n",
    "    # get results for LinearSVC\n",
    "    model_lsvc = LinearSVC(penalty='l2', C=1)\n",
    "    model_lsvc.fit(Xt_tfidf3, Yt)\n",
    "    results['lsvc'] = model_lsvc.score(Xv_tfidf3, Yv)\n",
    "    print('>>>', 'lsvc =', results['lsvc'])\n",
    "    # load pre-gathered BERT results\n",
    "    _, _, Yt, Yp, _ = load_bert_test_results(sample_name)\n",
    "    results['bert'] = accuracy_score(Yt, Yp)\n",
    "    print('>>>', 'bert =', results['bert'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e768354e-7d77-417b-bc2e-da119ef83849",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = [\n",
    "    'eng_any_any_100000', 'eng_any_long_100000', 'eng_any_short_100000',\n",
    "    'eng_eq_any_100000', 'eng_eq_long_100000', 'eng_eq_short_100000',\n",
    "    'any_any_any_100000', 'any_any_long_100000', 'any_any_short_100000',\n",
    "    'any_eq_any_100000', 'any_eq_long_100000', 'any_eq_short_100000',\n",
    "]\n",
    "seed = 1337\n",
    "test_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5b1c0-a5a4-4c4c-9c66-ceb1c5bf6693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    print(f'=== {sample_name} ===')\n",
    "    test_results[sample_name] = get_base_results_for_sample(sample_name, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfcaf0-1aae-4d0c-98ff-380a29a8fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b33a4f0-ab97-48d3-9096-4dcaafd55e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot Sample Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d486b-751f-4f0f-af0f-e0d3c15c591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_scores(sample_name, results):\n",
    "    keys_to_labels = {\n",
    "        'bl': 'Baseline', 'mnb': 'MNB', 'cnb': 'CNB',\n",
    "        'sgd': 'SGD', 'lsvc': 'SVC', 'bert': 'BERT'\n",
    "    }\n",
    "    X, Y, labels = [], [], []\n",
    "    for i, (key, value) in enumerate(results[sample_name].items()):\n",
    "        X.append(i)\n",
    "        Y.append(value)\n",
    "        labels.append(keys_to_labels[key])\n",
    "    plt.rcParams['xtick.direction'] = 'out'\n",
    "    ax = plt.gca()\n",
    "    ax = init_ax(ax, only_vertical=True)\n",
    "    plt.bar(X, Y, color='darkgrey')\n",
    "    ymin = 0.4 if results[sample_name]['bl'] < 0.55 else 0.6\n",
    "    plt.ylim([ymin, 1.0])\n",
    "    plt.xticks(X, labels)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Model')\n",
    "    plt.savefig(DIR_FIGS + f'bars_optimal_{sample_name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847d580-07e7-48ad-8ce7-83c41cb6152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in sample_names:\n",
    "    plot_sample_scores(sample_name, test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8ed73-eb2a-4b76-bd8b-159095ffcf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot ROC and Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2cee92c-b1d6-4aeb-9afb-05bbbcec40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_roc_cm(sample_name, seed=None, class_reports=False):\n",
    "    # load sample data\n",
    "    train, validation = read_data(sample_name, seed=seed)\n",
    "    Xt, Yt = train['text'].tolist(), train['polarity'].tolist()\n",
    "    Xv, Yv = validation['text'].tolist(), validation['polarity'].tolist()\n",
    "    # vectorise sample data\n",
    "    tfidf3 = TfidfVectorizer(ngram_range=(1, 3), binary=True, smooth_idf=False)\n",
    "    Xt_tfidf3 = tfidf3.fit_transform(Xt)\n",
    "    Xv_tfidf3 = tfidf3.transform(Xv)\n",
    "    tfidf4 = TfidfVectorizer(ngram_range=(1, 4), binary=True, smooth_idf=False)\n",
    "    Xt_tfidf4 = tfidf4.fit_transform(Xt)\n",
    "    Xv_tfidf4 = tfidf4.transform(Xv)\n",
    "    # get baseline results\n",
    "    model_bl = DummyClassifier(strategy='most_frequent')\n",
    "    model_bl.fit(Xt, Yt)\n",
    "    Ypred_bl = model_bl.predict(Xv)\n",
    "    Yp_bl = model_bl.predict_proba(Xv)[:,1]\n",
    "    fpr_bl, tpr_bl, _ = roc_curve(Yv, Yp_bl, pos_label=1)\n",
    "    prec_bl, rec_bl, _ = precision_recall_curve(Yv, Yp_bl, pos_label=1)\n",
    "    # get model results depending on sample\n",
    "    if sample_name in ['eng_any_long_100000', 'any_any_any_100000', 'any_any_long_100000']:\n",
    "        comp_label = 'SVC'\n",
    "        model_comp = LinearSVC(penalty='l2', C=1, max_iter=100)\n",
    "        model_comp.fit(Xt_tfidf3, Yt)\n",
    "        Ypred_comp = model_comp.predict(Xv_tfidf3)\n",
    "        Yp_comp = model_comp.decision_function(Xv_tfidf3)\n",
    "    elif sample_name in ['any_eq_short_100000']:\n",
    "        comp_label = 'CNB'\n",
    "        model_comp = ComplementNB(alpha=1)\n",
    "        model_comp.fit(Xt_tfidf4, Yt)\n",
    "        Ypred_comp = model_comp.predict(Xv_tfidf4)\n",
    "        Yp_comp = model_comp.predict_proba(Xv_tfidf4)[:,1]\n",
    "    else:\n",
    "        comp_label = 'SGD'\n",
    "        model_comp = SGDClassifier(penalty='l2', alpha=1e-5)\n",
    "        model_comp.fit(Xt_tfidf3, Yt)\n",
    "        Ypred_comp = model_comp.predict(Xv_tfidf3)\n",
    "        Yp_comp = model_comp.decision_function(Xv_tfidf3)\n",
    "    fpr_comp, tpr_comp, _ = roc_curve(Yv, Yp_comp, pos_label=1)\n",
    "    prec_comp, rec_comp, _ = precision_recall_curve(Yv, Yp_comp, pos_label=1)\n",
    "    auc_comp = round(auc(fpr_comp, tpr_comp), 3)\n",
    "    # load pre-gathered bert results\n",
    "    _, _, Yt_bert, Yp_bert, Yp_proba = load_bert_test_results(sample_name)\n",
    "    fpr_bert, tpr_bert, _ = roc_curve(Yt_bert, Yp_proba[:,1], pos_label=1)\n",
    "    prec_bert, rec_bert, _ = precision_recall_curve(Yt_bert, Yp_proba[:,1], pos_label=1)\n",
    "    auc_bert = round(auc(fpr_bert, tpr_bert), 3)\n",
    "    # print classification reports\n",
    "    if class_reports:\n",
    "        print(classification_report(Yv, Ypred_bl, zero_division=0))\n",
    "        print(classification_report(Yv, Ypred_comp, zero_division=0))\n",
    "        print(classification_report(Yv, Yp_bert, zero_division=0))\n",
    "        return\n",
    "    # plot roc curves\n",
    "    plt.plot(fpr_bert, tpr_bert, linestyle='--', color='#666', label=f'BERT (AUC $= {auc_bert}$)')\n",
    "    plt.plot(fpr_comp, tpr_comp, linestyle='--', color='#111', label=f'{comp_label} (AUC $= {auc_comp}$)')\n",
    "    plt.plot(fpr_bl, tpr_bl, linestyle='--', color='#aaa', label='Baseline')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.savefig(DIR_FIGS + f'roc_optimal_{sample_name}.png')\n",
    "    plt.show()\n",
    "    # plot precision/recall\n",
    "    plt.plot(rec_bert, prec_bert, linestyle='--', color='#666', label=f'BERT')\n",
    "    plt.plot(rec_comp, prec_comp, linestyle='--', color='#111', label=f'{comp_label}')\n",
    "    plt.plot(rec_bl, prec_bl, linestyle='--', color='#aaa', label=f'Baseline')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.savefig(DIR_FIGS + f'prec_optimal_{sample_name}.png')\n",
    "    plt.show()\n",
    "    # confusion matrices\n",
    "    plt.rcParams['xtick.direction'] = 'out'\n",
    "    plt.rcParams['ytick.direction'] = 'out'\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n",
    "    plt.subplots_adjust(bottom=0, left=0, top=1, right=1, wspace=-0.4)\n",
    "    def empty_func(_, ax=None): return\n",
    "    temp = fig.colorbar\n",
    "    fig.colorbar = empty_func\n",
    "    ax1.set_title('BERT')\n",
    "    ax2.set_title(f'{comp_label}')\n",
    "    cm_bert = confusion_matrix(Yt_bert, Yp_bert, labels=[0, 1])\n",
    "    disp_bert = ConfusionMatrixDisplay(cm_bert, display_labels=['Negative', 'Positive'])\n",
    "    disp_bert.plot(cmap='Greys', ax=ax1)\n",
    "    fig.colorbar = temp\n",
    "    cm_comp = confusion_matrix(Yv, Ypred_comp, labels=[0, 1])\n",
    "    disp_comp = ConfusionMatrixDisplay(cm_comp, display_labels=['Negative', 'Positive'])\n",
    "    disp_comp.plot(cmap='Greys', ax=ax2)\n",
    "    plt.savefig(DIR_FIGS + f'cm_optimal_{sample_name}.png')\n",
    "    plt.show()\n",
    "    init_plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d92c5ce6-869a-409b-b853-d27af528627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== eng_any_any_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1530\n",
      "           1       0.85      1.00      0.92      8470\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.42      0.50      0.46     10000\n",
      "weighted avg       0.72      0.85      0.78     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61      1530\n",
      "           1       0.92      0.95      0.94      8470\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.80      0.75      0.77     10000\n",
      "weighted avg       0.88      0.89      0.89     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.10      0.12      1530\n",
      "           1       0.85      0.89      0.87      8470\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.49      0.50      0.49     10000\n",
      "weighted avg       0.74      0.77      0.75     10000\n",
      "\n",
      "=== eng_any_long_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2090\n",
      "           1       0.79      1.00      0.88      7910\n",
      "\n",
      "    accuracy                           0.79     10000\n",
      "   macro avg       0.40      0.50      0.44     10000\n",
      "weighted avg       0.63      0.79      0.70     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      2090\n",
      "           1       0.92      0.94      0.93      7910\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.84      0.82      0.83     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.17      0.18      2090\n",
      "           1       0.79      0.83      0.81      7910\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.67      0.69      0.68     10000\n",
      "\n",
      "=== eng_any_short_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1266\n",
      "           1       0.87      1.00      0.93      8734\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.44      0.50      0.47     10000\n",
      "weighted avg       0.76      0.87      0.81     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.45      0.55      1266\n",
      "           1       0.92      0.97      0.95      8734\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.81      0.71      0.75     10000\n",
      "weighted avg       0.90      0.91      0.90     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.14      0.14      1266\n",
      "           1       0.88      0.88      0.88      8734\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.51      0.51      0.51     10000\n",
      "weighted avg       0.78      0.78      0.78     10000\n",
      "\n",
      "=== eng_eq_any_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5090\n",
      "           1       0.49      1.00      0.66      4910\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.24      0.49      0.32     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      5090\n",
      "           1       0.83      0.83      0.83      4910\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.50      5090\n",
      "           1       0.49      0.53      0.51      4910\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.50      0.50      0.50     10000\n",
      "\n",
      "=== eng_eq_long_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5090\n",
      "           1       0.49      1.00      0.66      4910\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.24      0.49      0.32     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      5090\n",
      "           1       0.86      0.85      0.86      4910\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.39      0.44      5090\n",
      "           1       0.49      0.62      0.55      4910\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.50      0.50      0.49     10000\n",
      "\n",
      "=== eng_eq_short_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5090\n",
      "           1       0.49      1.00      0.66      4910\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.24      0.49      0.32     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      5090\n",
      "           1       0.79      0.83      0.81      4910\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.81      0.81      0.81     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.52      0.52      5090\n",
      "           1       0.50      0.49      0.49      4910\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.51      0.51      0.51     10000\n",
      "weighted avg       0.51      0.51      0.51     10000\n",
      "\n",
      "=== any_any_any_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1301\n",
      "           1       0.87      1.00      0.93      8699\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.43      0.50      0.47     10000\n",
      "weighted avg       0.76      0.87      0.81     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.36      0.46      1301\n",
      "           1       0.91      0.97      0.94      8699\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.78      0.66      0.70     10000\n",
      "weighted avg       0.88      0.89      0.88     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.08      0.10      1301\n",
      "           1       0.87      0.91      0.89      8699\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.49      0.49      0.49     10000\n",
      "weighted avg       0.77      0.80      0.78     10000\n",
      "\n",
      "=== any_any_long_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1975\n",
      "           1       0.80      1.00      0.89      8025\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.40      0.50      0.45     10000\n",
      "weighted avg       0.64      0.80      0.71     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.56      0.64      1975\n",
      "           1       0.90      0.95      0.92      8025\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.82      0.76      0.78     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.16      0.17      1975\n",
      "           1       0.80      0.84      0.82      8025\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.68      0.70      0.69     10000\n",
      "\n",
      "=== any_any_short_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1101\n",
      "           1       0.89      1.00      0.94      8899\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.44      0.50      0.47     10000\n",
      "weighted avg       0.79      0.89      0.84     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.31      0.41      1101\n",
      "           1       0.92      0.98      0.95      8899\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.77      0.64      0.68     10000\n",
      "weighted avg       0.89      0.90      0.89     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.11      0.11      1101\n",
      "           1       0.89      0.90      0.89      8899\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.81      0.81      0.81     10000\n",
      "\n",
      "=== any_eq_any_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5090\n",
      "           1       0.49      1.00      0.66      4910\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.24      0.49      0.32     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78      5090\n",
      "           1       0.76      0.81      0.78      4910\n",
      "\n",
      "    accuracy                           0.78     10000\n",
      "   macro avg       0.78      0.78      0.78     10000\n",
      "weighted avg       0.78      0.78      0.78     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.49      5090\n",
      "           1       0.49      0.52      0.50      4910\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.50      0.50      0.50     10000\n",
      "\n",
      "=== any_eq_long_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5090\n",
      "           1       0.49      1.00      0.66      4910\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.24      0.49      0.32     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84      5090\n",
      "           1       0.84      0.83      0.83      4910\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.84      0.84      0.84     10000\n",
      "weighted avg       0.84      0.84      0.84     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.43      0.47      5090\n",
      "           1       0.50      0.58      0.54      4910\n",
      "\n",
      "    accuracy                           0.51     10000\n",
      "   macro avg       0.51      0.51      0.50     10000\n",
      "weighted avg       0.51      0.51      0.50     10000\n",
      "\n",
      "=== any_eq_short_100000 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5090\n",
      "           1       0.49      1.00      0.66      4910\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.25      0.50      0.33     10000\n",
      "weighted avg       0.24      0.49      0.32     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      5090\n",
      "           1       0.79      0.71      0.75      4910\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.76      0.76     10000\n",
      "weighted avg       0.77      0.77      0.76     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.49      5090\n",
      "           1       0.49      0.52      0.50      4910\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.50      0.50      0.50     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sample_name in sample_names:\n",
    "    print(f'=== {sample_name} ===')\n",
    "    plot_sample_roc_cm(sample_name, seed=seed, class_reports=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
