{"cells":[{"cell_type":"markdown","source":["# BERT Review Polarity"],"metadata":{"id":"9bkKxbueRhqN"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"oUfASVs77eqL"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"j4hhJe2XfkP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from transformers import DistilBertTokenizerFast\n","from transformers import TFDistilBertForSequenceClassification\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf"],"metadata":{"id":"LuQft7QqRTrl","executionInfo":{"status":"ok","timestamp":1647794344331,"user_tz":0,"elapsed":7,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n","tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"],"metadata":{"id":"05miZNUI6zDm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH_GDRIVE = '/content/drive'\n","drive.mount(PATH_GDRIVE, force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAMDpJh9A3Uf","executionInfo":{"status":"ok","timestamp":1647797004121,"user_tz":0,"elapsed":2972,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}},"outputId":"e6eb162c-9b11-40e6-f784-903f3da223aa"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# paths\n","DIR = 'drive/MyDrive/MSc Dissertation/data/'\n","PATH_SAMPLES = DIR + 'samples/review_polarity/%s.csv'\n","PATH_MODELS = DIR + 'models/review_polarity/%s_%d'\n","PATH_RESULTS = DIR + 'results/review_polarity/%s_%d'\n","# bert models\n","BERT_MODEL_ENG = 'distilbert-base-uncased'\n","BERT_MODEL_NENG = 'distilbert-base-multilingual-cased'"],"metadata":{"id":"O1CoHYcEBOdp","executionInfo":{"status":"ok","timestamp":1647796989502,"user_tz":0,"elapsed":213,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":["## Data Reading and Writing"],"metadata":{"id":"txQ45JA98VeN"}},{"cell_type":"code","source":["def read_data(sample_name, train_size=0.8, test_size=0.5, seed=None):\n","    df = pd.read_csv(PATH_SAMPLES % sample_name)[['polarity', 'text']].reset_index(drop=True)\n","    train, remaining = train_test_split(df, train_size=train_size, random_state=seed)\n","    validation, test = train_test_split(remaining, test_size=test_size, random_state=seed)\n","    return train, validation, test"],"metadata":{"id":"5sr4V2DGCuJH","executionInfo":{"status":"ok","timestamp":1647791799568,"user_tz":0,"elapsed":201,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def write_data_train(sample_name, run_num, train_history):\n","    with open((PATH_RESULTS % (sample_name, run_num)) + '_train.txt', 'w+') as f:\n","        f.write(str(train_history.params) + '\\n')\n","        f.write(str(train_history.history) + '\\n')"],"metadata":{"id":"PFyPLLMS_J_s","executionInfo":{"status":"ok","timestamp":1647796964699,"user_tz":0,"elapsed":4,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["def write_data_test(sample_name, run_num, Y_test, Y_pred):\n","    with open((PATH_RESULTS % (sample_name, run_num)) + '_test.txt', 'w+') as f:\n","        f.write(str(Y_test) + '\\n')\n","        f.write(str(Y_pred) + '\\n')"],"metadata":{"id":"diQNGrYKGZQm","executionInfo":{"status":"ok","timestamp":1647796962065,"user_tz":0,"elapsed":220,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":["## Model Training and Testing\n"],"metadata":{"id":"7aTEMj-B8iLV"}},{"cell_type":"code","source":["def train_model(sample_name, train_data, validation_data, run_num=0, num_epochs=2, batch_size=16, learning_rate=5e-5, seed=None):\n","    with tpu_strategy.scope():\n","        # load pre-trained stuff\n","        if sample_name.startswith('eng'): model_name = BERT_MODEL_ENG\n","        else: model_name = BERT_MODEL_NENG\n","        tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n","        classifier = TFDistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","        # separate data\n","        Xt, Yt = train_data['text'].tolist(), train_data['polarity'].tolist()\n","        Xv, Yv = validation_data['text'].tolist(), validation_data['polarity'].tolist()\n","        # encode and format data\n","        encode = lambda x: tokenizer(x, truncation=True, padding=True, return_tensors='tf')\n","        format = lambda x, y: tf.data.Dataset.from_tensor_slices((dict(x), y)).shuffle(100, seed=seed)\n","        train_data = format(encode(Xt), Yt)\n","        validation_data = format(encode(Xv), Yv)\n","        # train and save the model\n","        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-8)\n","        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        classifier.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","    fit_results = classifier.fit(\n","        train_data.batch(batch_size),\n","        epochs=num_epochs,\n","        batch_size=batch_size,\n","        validation_data=validation_data.batch(batch_size)\n","    )\n","    classifier.save_pretrained(PATH_MODELS % (sample_name, run_num))\n","    write_data_train(sample_name, run_num, fit_results)"],"metadata":{"id":"Y7RS9_G8FPcm","executionInfo":{"status":"ok","timestamp":1647796966961,"user_tz":0,"elapsed":190,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["def test_model(sample_name, test_data, run_num=0, batch_size=16, seed=None):\n","    with tpu_strategy.scope():\n","        # load pre-trained stuff\n","        if sample_name.startswith('eng'): model_name = BERT_MODEL_ENG\n","        else: model_name = BERT_MODEL_NENG\n","        tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n","        classifier = TFDistilBertForSequenceClassification.from_pretrained(PATH_MODELS % (sample_name, run_num), num_labels=2)\n","        # separate data\n","        Xt, Yt = test_data['text'].tolist(), test_data['polarity'].tolist()\n","        # encode, format and convert data\n","        encode = lambda x: tokenizer(x, truncation=True, padding=True, return_tensors='tf')\n","        format = lambda x: tf.data.Dataset.from_tensor_slices(dict(x))\n","        convert = lambda y: tf.argmax(tf.nn.softmax(y.logits, axis=1), axis=1).numpy()[::8]\n","        Xt = format(encode(Xt))\n","        Yp = convert(classifier.predict(Xt)).tolist()\n","    write_data_test(sample_name, run_num, Yt, Yp)"],"metadata":{"id":"6tYJBHi0DeSy","executionInfo":{"status":"ok","timestamp":1647796969431,"user_tz":0,"elapsed":235,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":["## Running Everything"],"metadata":{"id":"UxbYqpXg8qku"}},{"cell_type":"code","source":["batch_sizes = [16, 32, 64]\n","num_epochs = [2, 3, 4]\n","run_num = 0\n","sample_name = 'eng_eq_any_100000'\n","seed = 1337\n","train, validation, test = read_data(sample_name, seed=seed)"],"metadata":{"id":"G2zqYmm-YYaR","executionInfo":{"status":"ok","timestamp":1647799572634,"user_tz":0,"elapsed":1415,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["for batch_size in batch_sizes:\n","    for num_epoch in num_epochs:\n","        print(f'=== RUN_NUM={run_num} ===')\n","        train_model(sample_name, train, validation, run_num=run_num, seed=seed, batch_size=batch_size, num_epochs=num_epoch)\n","        test_model(sample_name, test, run_num=run_num, seed=seed, batch_size=batch_size)\n","        run_num += 1"],"metadata":{"id":"WKF6340cPAro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_names = [\n","    'eng_any_any_100000', 'eng_any_long_100000', 'eng_any_short_100000',\n","    'eng_eq_any_100000', 'eng_eq_long_100000', 'eng_eq_short_100000',\n","    'any_any_any_100000', 'any_any_long_100000', 'any_any_short_100000',\n","    'any_eq_any_100000', 'any_eq_long_100000', 'any_eq_short_100000',\n","]\n","seed=1337"],"metadata":{"id":"aIPgaTbrDQW5","executionInfo":{"status":"ok","timestamp":1647808662018,"user_tz":0,"elapsed":246,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["for sample_name in sample_names:\n","    train, validation, test = read_data(sample_name, seed=seed)\n","    train_model(sample_name, train, validation, run_num=10, batch_size=32, seed=seed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LYCcqXG1gjgA","executionInfo":{"status":"ok","timestamp":1647817312118,"user_tz":0,"elapsed":7877752,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}},"outputId":"6508eb68-36b0-4f4d-d093-9fc3d8b39575"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_719']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 302s 99ms/step - loss: 0.2483 - accuracy: 0.9022 - val_loss: 0.2261 - val_accuracy: 0.9135\n","Epoch 2/2\n","2500/2500 [==============================] - 233s 93ms/step - loss: 0.1823 - accuracy: 0.9324 - val_loss: 0.2507 - val_accuracy: 0.9120\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_739']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 303s 99ms/step - loss: 0.2481 - accuracy: 0.9017 - val_loss: 0.2219 - val_accuracy: 0.9147\n","Epoch 2/2\n","2500/2500 [==============================] - 233s 93ms/step - loss: 0.1729 - accuracy: 0.9383 - val_loss: 0.2525 - val_accuracy: 0.9119\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_759']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 301s 99ms/step - loss: 0.2368 - accuracy: 0.9086 - val_loss: 0.2178 - val_accuracy: 0.9217\n","Epoch 2/2\n","2500/2500 [==============================] - 233s 93ms/step - loss: 0.1773 - accuracy: 0.9364 - val_loss: 0.2281 - val_accuracy: 0.9136\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_779']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 302s 99ms/step - loss: 0.3665 - accuracy: 0.8477 - val_loss: 0.3336 - val_accuracy: 0.8684\n","Epoch 2/2\n","2500/2500 [==============================] - 233s 93ms/step - loss: 0.2779 - accuracy: 0.8975 - val_loss: 0.3509 - val_accuracy: 0.8637\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_799']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 302s 99ms/step - loss: 0.3098 - accuracy: 0.8789 - val_loss: 0.2867 - val_accuracy: 0.8941\n","Epoch 2/2\n","2500/2500 [==============================] - 235s 94ms/step - loss: 0.2254 - accuracy: 0.9216 - val_loss: 0.3300 - val_accuracy: 0.8841\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_819']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 301s 99ms/step - loss: 0.3844 - accuracy: 0.8379 - val_loss: 0.3470 - val_accuracy: 0.8606\n","Epoch 2/2\n","2500/2500 [==============================] - 233s 93ms/step - loss: 0.2966 - accuracy: 0.8875 - val_loss: 0.3767 - val_accuracy: 0.8519\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_839']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 340s 114ms/step - loss: 0.2997 - accuracy: 0.8836 - val_loss: 0.2701 - val_accuracy: 0.8942\n","Epoch 2/2\n","2500/2500 [==============================] - 272s 109ms/step - loss: 0.2115 - accuracy: 0.9196 - val_loss: 0.2819 - val_accuracy: 0.8921\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_859']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 343s 114ms/step - loss: 0.3317 - accuracy: 0.8605 - val_loss: 0.2653 - val_accuracy: 0.8899\n","Epoch 2/2\n","2500/2500 [==============================] - 273s 109ms/step - loss: 0.2206 - accuracy: 0.9141 - val_loss: 0.2924 - val_accuracy: 0.8883\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_879']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 341s 114ms/step - loss: 0.2850 - accuracy: 0.8923 - val_loss: 0.2573 - val_accuracy: 0.9008\n","Epoch 2/2\n","2500/2500 [==============================] - 273s 109ms/step - loss: 0.2116 - accuracy: 0.9207 - val_loss: 0.2653 - val_accuracy: 0.8961\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_899']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 340s 114ms/step - loss: 0.4727 - accuracy: 0.7760 - val_loss: 0.4204 - val_accuracy: 0.8157\n","Epoch 2/2\n","2500/2500 [==============================] - 274s 109ms/step - loss: 0.3478 - accuracy: 0.8573 - val_loss: 0.4483 - val_accuracy: 0.8090\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_919']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 342s 114ms/step - loss: 0.4169 - accuracy: 0.8119 - val_loss: 0.3444 - val_accuracy: 0.8579\n","Epoch 2/2\n","2500/2500 [==============================] - 273s 109ms/step - loss: 0.2860 - accuracy: 0.8884 - val_loss: 0.3614 - val_accuracy: 0.8583\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_projector', 'activation_13', 'vocab_transform', 'vocab_layer_norm']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier', 'pre_classifier', 'dropout_939']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2500/2500 [==============================] - 344s 116ms/step - loss: 0.4856 - accuracy: 0.7699 - val_loss: 0.4489 - val_accuracy: 0.7960\n","Epoch 2/2\n","2500/2500 [==============================] - 273s 109ms/step - loss: 0.3676 - accuracy: 0.8466 - val_loss: 0.4817 - val_accuracy: 0.8002\n"]}]},{"cell_type":"code","source":["for sample_name in sample_names:\n","    _, _, test = read_data(sample_name, seed=seed)\n","    test_model(sample_name, test, run_num=10, batch_size=32, seed=seed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skpiHf66DTU5","executionInfo":{"status":"ok","timestamp":1647818955564,"user_tz":0,"elapsed":1637223,"user":{"displayName":"Conor Mac Amhlaoibh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcKid0uXS4g54xrwj4CVpE-lHwAh9uoDVu6zcdaA=s64","userId":"03538415382823304994"}},"outputId":"762c6113-3abc-4a0b-c0ff-a08e4460241b"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_any_any_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_719']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_any_any_100000_10 and are newly initialized: ['dropout_959']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_any_long_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_739']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_any_long_100000_10 and are newly initialized: ['dropout_979']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_any_short_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_759']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_any_short_100000_10 and are newly initialized: ['dropout_999']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_eq_any_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_779']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_eq_any_100000_10 and are newly initialized: ['dropout_1019']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_eq_long_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_799']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_eq_long_100000_10 and are newly initialized: ['dropout_1039']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_eq_short_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_819']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/eng_eq_short_100000_10 and are newly initialized: ['dropout_1059']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_any_any_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_839']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_any_any_100000_10 and are newly initialized: ['dropout_1079']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_any_long_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_859']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_any_long_100000_10 and are newly initialized: ['dropout_1099']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_any_short_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_879']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_any_short_100000_10 and are newly initialized: ['dropout_1119']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_eq_any_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_899']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_eq_any_100000_10 and are newly initialized: ['dropout_1139']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_eq_long_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_919']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_eq_long_100000_10 and are newly initialized: ['dropout_1159']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_eq_short_100000_10 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_939']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Dissertation/data/models/review_polarity/any_eq_short_100000_10 and are newly initialized: ['dropout_1179']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]}],"metadata":{"interpreter":{"hash":"c033a5045b155981ee72213b5a792ae49fdd09af88109a854dac011f87e13240"},"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"orig_nbformat":4,"colab":{"name":"BERT Review Polarity.ipynb","provenance":[{"file_id":"https://github.com/conormccauley1999/MScDissertation/blob/main/notebooks/BERTReviewSentiment.ipynb","timestamp":1642123997565}],"collapsed_sections":[]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}